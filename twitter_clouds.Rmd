---
title: "Twitter Word Clouds"
author: "Chi Yan Tang"
date: "23 July 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Word cloud visualisation of tweets. This code is adapted from the "Intro-to-text-mining-bag-of-words" DataCamp course. Tweets are obtained using the R "twitteR" package.

```{r}
options(warn=-1) #surpress warnings

library(qdap, quietly = TRUE, warn.conflicts=FALSE)
library(tm, quietly = TRUE, warn.conflicts=FALSE)
library(twitteR, quietly = TRUE, warn.conflicts=FALSE)
library(ROAuth, quietly = TRUE, warn.conflicts=FALSE)
library(httr, quietly = TRUE, warn.conflicts=FALSE)
library(wordcloud, quietly = TRUE, warn.conflicts=FALSE)

#API Keys, OAuth access tokens need to be supplied
#https://dev.twitter.com/oauth/overview/application-owner-access-tokens
api_key <- "..."
api_secret <- "..."
access_token <- "..."
access_token_secret <- "..."
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)

#Source: https://stackoverflow.com/questions/14281282/how-to-write-custom-removepunctuation-function-to-better-deal-with-unicode-cha 
removeNonAlnum <- function(x){
  gsub("[^[:alnum:]^[:space:]]","",x)
}

removeNonAlphabet <- function(x){
  gsub("[^[:alpha:]^[:space:]]","",x)
}

removeHttp <- function(x){
  gsub("http\\S+\\s*", "", x)
}
clean_corpus <- function(corpus, term){
 corpus <- tm_map(corpus, content_transformer(removeNonAlnum))
  corpus <- tm_map(corpus, content_transformer(removeNonAlphabet))
  corpus <- tm_map(corpus, content_transformer(removeHttp))
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, c(stopwords("en"),term,substring(term,2)))
 
  return(corpus)
}

word_cloud <- function(term)
{
  #searches Twitter and converts to data frame
  tweets = twListToDF(searchTwitter(term, n=2000))$text

  vec_source = VectorSource(tweets)
  vec_corp = VCorpus(vec_source)

  #cleans corpus
  clean_corp = clean_corpus(vec_corp, term) #to view corp, use as.data.frame(clean_corp)$text

  #converts corpus to term-document matrix
  tdm = TermDocumentMatrix(clean_corp)
  tdm_matrix = as.matrix(tdm)
  term_frequency = rowSums(tdm_matrix)
  term_frequency <- sort(term_frequency, decreasing = TRUE)
  word_freqs = data.frame(term=names(term_frequency), num = term_frequency)
  blues <- brewer.pal(9, "Blues")[3:9] #prebuilt colour palette, choose darker colours
  wordcloud(word_freqs$term, word_freqs$num, max.words = Inf, scale=c(3,.2),min.freq=20, colors = blues)
}

word_cloud("#australia")
word_cloud("#malaysia")
word_cloud("#singapore")
word_cloud("#uk")
word_cloud("#usa")
```